{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from train_sae.models.transformer import trunk_and_head_from_pretrained\n",
    "from train_sae.saes.crosscoder import CrossCoderSAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2347464/3955769390.py:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(\"./model_25000_flops_1.61e+14.pt\", map_location=device)\n",
      "/home/cadegord/projects/train-SAE/train_sae/models/transformer.py:284: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda:7\"\n",
    "addition_cc = CrossCoderSAE(2, 128, 2048, \"vanilla\", {\"sparsity\": 0.01}).to(device)\n",
    "addition_cc.load_state_dict(\n",
    "    torch.load(\"./model_25000_flops_1.61e+14.pt\", map_location=device)\n",
    ")\n",
    "\n",
    "pre_feat, pre_decoder = trunk_and_head_from_pretrained(\n",
    "    \"./1100-train=1.00-test=0.53.pt\",\n",
    "    1,\n",
    "    device,\n",
    "    torch.float32,\n",
    "    99,\n",
    "    128,\n",
    "    512,\n",
    "    4,\n",
    "    2,\n",
    "    use_geglu=False,\n",
    "    max_seq_len=2048,\n",
    "    use_learned_pos_emb=True,\n",
    "    norm_layer=\"LayerNorm\",\n",
    ")\n",
    "post_feat, post_decoder = trunk_and_head_from_pretrained(\n",
    "    \"./1700-train=1.00-test=1.00.pt\",\n",
    "    1,\n",
    "    device,\n",
    "    torch.float32,\n",
    "    99,\n",
    "    128,\n",
    "    512,\n",
    "    4,\n",
    "    2,\n",
    "    use_geglu=False,\n",
    "    max_seq_len=2048,\n",
    "    use_learned_pos_emb=True,\n",
    "    norm_layer=\"LayerNorm\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "addition_dec1_weights = addition_cc.autoencoders[0].decoder.weight.detach()\n",
    "addition_dec2_weights = addition_cc.autoencoders[1].decoder.weight.detach()\n",
    "addition_dec1_weight_norms = addition_dec1_weights.norm(dim=0)\n",
    "addition_dec2_weight_norms = addition_dec2_weights.norm(dim=0)\n",
    "\n",
    "addition_relative_norms = addition_dec1_weight_norms / (\n",
    "    addition_dec1_weight_norms + addition_dec2_weight_norms\n",
    ")\n",
    "addition_relative_norms = addition_relative_norms.numpy(force=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create train and test addition data\n",
    "from itertools import product\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "prime = 97\n",
    "\n",
    "data = []\n",
    "for a, b in product(range(prime), range(prime)):\n",
    "    data.append([a, 97, b, 98, (a + b) % prime])\n",
    "\n",
    "data = torch.tensor(data)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "train_data, test_data = torch.utils.data.random_split(\n",
    "    data, [0.5, 0.5], generator=generator\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=512,\n",
    "    shuffle=False,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre train accuracy: 1.0\n",
      "Post train accuracy: 1.0\n",
      "Pre test accuracy: 0.5318877551020408\n",
      "Post test accuracy: 0.9963860544217688\n"
     ]
    }
   ],
   "source": [
    "all_data = []\n",
    "pre_generalization_data = []\n",
    "post_generalization_data = []\n",
    "all_encoded = []\n",
    "pre_generalization_is_correct = []\n",
    "post_generalization_is_correct = []\n",
    "\n",
    "# get train and test accuracy with a cross coder\n",
    "pre_train_correct = 0\n",
    "pre_train_total = 0\n",
    "post_train_correct = 0\n",
    "post_train_total = 0\n",
    "for batch in train_dataloader:\n",
    "    batch = batch.long()\n",
    "    batch = batch.to(device)\n",
    "    all_data.append(batch)\n",
    "    x, y = batch[:, :4], batch[:, 4]\n",
    "    with torch.no_grad():\n",
    "        zs = [pre_feat(x), post_feat(x)]\n",
    "        z_normalizing_factors = [\n",
    "            pre_feat.embed_dim**0.5 / z.norm(dim=-1, keepdim=True) for z in zs\n",
    "        ]\n",
    "        zs = [z * z_normalizing_factors[i] for i, z in enumerate(zs)]\n",
    "        pre_generalization_data.append(addition_cc.autoencoders[0].encoder(zs[0]))\n",
    "        post_generalization_data.append(addition_cc.autoencoders[1].encoder(zs[1]))\n",
    "        encoded_pre_activation = (\n",
    "            pre_generalization_data[-1] + post_generalization_data[-1]\n",
    "        )\n",
    "        encoded = addition_cc.activation_fn(encoded_pre_activation)\n",
    "        all_encoded.append(encoded)\n",
    "        # encoded = addition_cc.encode(zs)\n",
    "        z_hats = [\n",
    "            autoencoder.decoder(encoded) for autoencoder in addition_cc.autoencoders\n",
    "        ]\n",
    "        z_hats = [z_hat / z_normalizing_factors[i] for i, z_hat in enumerate(z_hats)]\n",
    "        pre_preds = pre_decoder(z_hats[0])[:, -1, :]\n",
    "        post_preds = post_decoder(z_hats[1])[:, -1, :]\n",
    "        pre_generalization_is_correct.append(pre_preds.argmax(dim=1) == y)\n",
    "        post_generalization_is_correct.append(post_preds.argmax(dim=1) == y)\n",
    "        pre_train_correct += pre_generalization_is_correct[-1].sum().item()\n",
    "        pre_train_total += y.size(0)\n",
    "        post_train_correct += post_generalization_is_correct[-1].sum().item()\n",
    "        post_train_total += y.size(0)\n",
    "print(f\"Pre train accuracy: {pre_train_correct / pre_train_total}\")\n",
    "print(f\"Post train accuracy: {post_train_correct / post_train_total}\")\n",
    "\n",
    "pre_test_correct = 0\n",
    "pre_test_total = 0\n",
    "post_test_correct = 0\n",
    "post_test_total = 0\n",
    "for batch in test_dataloader:\n",
    "    batch = batch.long()\n",
    "    batch = batch.to(device)\n",
    "    all_data.append(batch)\n",
    "    x, y = batch[:, :4], batch[:, 4]\n",
    "    with torch.no_grad():\n",
    "        zs = [pre_feat(x), post_feat(x)]\n",
    "        z_normalizing_factors = [\n",
    "            pre_feat.embed_dim**0.5 / z.norm(dim=-1, keepdim=True) for z in zs\n",
    "        ]\n",
    "        zs = [z * z_normalizing_factors[i] for i, z in enumerate(zs)]\n",
    "        pre_generalization_data.append(addition_cc.autoencoders[0].encoder(zs[0]))\n",
    "        post_generalization_data.append(addition_cc.autoencoders[1].encoder(zs[1]))\n",
    "        encoded_pre_activation = (\n",
    "            pre_generalization_data[-1] + post_generalization_data[-1]\n",
    "        )\n",
    "        encoded = addition_cc.activation_fn(encoded_pre_activation)\n",
    "        all_encoded.append(encoded)\n",
    "        # encoded = addition_cc.encode(zs)\n",
    "        z_hats = [\n",
    "            autoencoder.decoder(encoded) for autoencoder in addition_cc.autoencoders\n",
    "        ]\n",
    "        z_hats = [z_hat / z_normalizing_factors[i] for i, z_hat in enumerate(z_hats)]\n",
    "        pre_preds = pre_decoder(z_hats[0])[:, -1, :]\n",
    "        post_preds = post_decoder(z_hats[1])[:, -1, :]\n",
    "        pre_generalization_is_correct.append(pre_preds.argmax(dim=1) == y)\n",
    "        post_generalization_is_correct.append(post_preds.argmax(dim=1) == y)\n",
    "        pre_test_correct += pre_generalization_is_correct[-1].sum().item()\n",
    "        pre_test_total += y.size(0)\n",
    "        post_test_correct += post_generalization_is_correct[-1].sum().item()\n",
    "        post_test_total += y.size(0)\n",
    "print(f\"Pre test accuracy: {pre_test_correct / pre_test_total}\")\n",
    "print(f\"Post test accuracy: {post_test_correct / post_test_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = torch.cat(all_data)\n",
    "all_encoded = torch.cat(all_encoded)\n",
    "pre_generalization_data = torch.cat(pre_generalization_data)\n",
    "post_generalization_data = torch.cat(post_generalization_data)\n",
    "pre_generalization_is_correct = torch.cat(pre_generalization_is_correct)\n",
    "post_generalization_is_correct = torch.cat(post_generalization_is_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_zeros = torch.zeros(all_data.shape[0], 1, 2048).to(device)\n",
    "all_encoded = torch.cat([all_encoded, padding_zeros], dim=1)\n",
    "pre_generalization_data = torch.cat([pre_generalization_data, padding_zeros], dim=1)\n",
    "post_generalization_data = torch.cat([post_generalization_data, padding_zeros], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9409, 5, 2048])\n",
      "torch.Size([9409, 5, 2048])\n",
      "torch.Size([9409, 5, 2048])\n",
      "torch.Size([9409, 5])\n",
      "torch.Size([9409])\n",
      "torch.Size([9409])\n"
     ]
    }
   ],
   "source": [
    "print(all_encoded.shape)\n",
    "print(pre_generalization_data.shape)\n",
    "print(post_generalization_data.shape)\n",
    "print(all_data.shape)\n",
    "print(pre_generalization_is_correct.shape)\n",
    "print(post_generalization_is_correct.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets\n",
    "from IPython.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 900x180 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_slider_plot(value):\n",
    "    # Ensure the value is between 0 and 1\n",
    "    value = max(0, min(1, value))\n",
    "    value = 1 - value  # done to match the dashoard\n",
    "\n",
    "    # Create the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 2), dpi=90)\n",
    "\n",
    "    # Create the horizontal line\n",
    "    ax.plot([0, 1], [0, 0], \"k-\", linewidth=2)\n",
    "\n",
    "    # Add vertical ticks at the ends\n",
    "    ax.plot([0, 0], [-0.05, 0.05], \"k-\", linewidth=2)  # Left tick\n",
    "    ax.plot([1, 1], [-0.05, 0.05], \"k-\", linewidth=2)  # Right tick\n",
    "\n",
    "    # Place the dot at the value position\n",
    "    ax.plot(value, 0, \"o\", markersize=12, color=\"black\")\n",
    "\n",
    "    # Add the labels\n",
    "    ax.text(0, -0.15, \"Pre-Generalization\\nOnly\", ha=\"center\", va=\"top\", fontsize=12)\n",
    "    ax.text(0.5, -0.15, \"Shared\", ha=\"center\", va=\"top\", fontsize=12)\n",
    "    ax.text(1, -0.15, \"Post-Generalization\\nOnly\", ha=\"center\", va=\"top\", fontsize=12)\n",
    "\n",
    "    # Remove axis ticks and labels\n",
    "    ax.set_xlim(-0.1, 1.1)\n",
    "    ax.set_ylim(-0.5, 0.5)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "# Example usage with a value of 0.3\n",
    "value = 0.3\n",
    "fig = create_slider_plot(value)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ideas:\n",
    "# histogram of the crosscoder activations\n",
    "# show the predicted value instead of the target\n",
    "# add various hovering capabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5b3a10380ed4cd0b7803fe83e131452",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='←', layout=Layout(width='40px'), style=ButtonStyle()), Dropd…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "TOPK = 20\n",
    "# Create dropdown for selecting data element\n",
    "dropdown = ipywidgets.Dropdown(\n",
    "    options=[(f\"Element {i}\", i) for i in range(all_encoded.shape[2])],\n",
    "    value=0,\n",
    "    description=\"Select:\",\n",
    ")\n",
    "\n",
    "# Create forward and back buttons\n",
    "back_button = ipywidgets.Button(description=\"←\", layout=ipywidgets.Layout(width=\"40px\"))\n",
    "forward_button = ipywidgets.Button(\n",
    "    description=\"→\", layout=ipywidgets.Layout(width=\"40px\")\n",
    ")\n",
    "\n",
    "\n",
    "def token_to_text(token):\n",
    "    if token == 97:\n",
    "        return \"+\"\n",
    "    elif token == 98:\n",
    "        return \"=\"\n",
    "    else:\n",
    "        return token\n",
    "\n",
    "\n",
    "def on_back_button_clicked(b):\n",
    "    if dropdown.value > 0:\n",
    "        dropdown.value -= 1\n",
    "\n",
    "\n",
    "def on_forward_button_clicked(b):\n",
    "    if dropdown.value < len(all_data) - 1:\n",
    "        dropdown.value += 1\n",
    "\n",
    "\n",
    "# Pre-compute all HTML for faster rendering\n",
    "@functools.lru_cache(maxsize=32)  # Cache the results to avoid recomputation\n",
    "def generate_html_for_element(element_idx):\n",
    "    \"\"\"Generate all the HTML needed for a specific element index\"\"\"\n",
    "    html_parts = []\n",
    "\n",
    "    # Add column headers HTML\n",
    "    headers_html = (\n",
    "        '<div style=\"display: flex; align-items: center; margin-bottom: 10px;\">'\n",
    "    )\n",
    "    headers_html += '<span style=\"width: 50px;\"></span>'\n",
    "    headers_html += (\n",
    "        '<span style=\"font-weight: bold; margin-right: 55px;\">Pre-generalization</span>'\n",
    "    )\n",
    "    headers_html += '<span style=\"margin: 0 10px;\">|</span>'\n",
    "    headers_html += (\n",
    "        '<span style=\"font-weight: bold; margin-right: 55px;\">'\n",
    "        \"Crosscoder Features\"\n",
    "        \"</span>\"\n",
    "    )\n",
    "    headers_html += '<span style=\"margin: 0 10px;\">|</span>'\n",
    "    headers_html += '<span style=\"font-weight: bold;\">Post-generalization</span>'\n",
    "    headers_html += \"</div>\"\n",
    "\n",
    "    idx = torch.argsort(\n",
    "        torch.max(all_encoded[:, :, element_idx], dim=1)[0], descending=True\n",
    "    )[:TOPK]\n",
    "    data_reordered = all_data[idx]\n",
    "\n",
    "    selected_data_l = pre_generalization_data[idx, :, element_idx]\n",
    "    selected_data_l_min = torch.min(selected_data_l)\n",
    "    selected_data_l_max = torch.max(selected_data_l)\n",
    "    selected_data_l_correct = pre_generalization_is_correct[idx]\n",
    "\n",
    "    selected_data_c = all_encoded[idx, :, element_idx]\n",
    "    selected_data_c_max = torch.max(selected_data_c)\n",
    "\n",
    "    selected_data_r = post_generalization_data[idx, :, element_idx]\n",
    "    selected_data_r_min = torch.min(selected_data_r)\n",
    "    selected_data_r_max = torch.max(selected_data_r)\n",
    "    selected_data_r_correct = post_generalization_is_correct[idx]\n",
    "    selected_data_lr_max = max(\n",
    "        selected_data_l_max,\n",
    "        selected_data_r_max,\n",
    "        abs(selected_data_l_min),\n",
    "        abs(selected_data_r_min),\n",
    "    )\n",
    "\n",
    "    # Base style string\n",
    "    base_style = (\n",
    "        \"padding: 5px; border-radius: 5px; margin: 2px; display: inline-block;\"\n",
    "        \" width: 20px; height: 28px; text-align: center; overflow: hidden;\"\n",
    "    )\n",
    "\n",
    "    # Create rows HTML\n",
    "    for idx, (\n",
    "        text_data,\n",
    "        row_data_l,\n",
    "        row_data_c,\n",
    "        row_data_r,\n",
    "        row_data_l_correct,\n",
    "        row_data_r_correct,\n",
    "    ) in enumerate(\n",
    "        zip(\n",
    "            data_reordered,\n",
    "            selected_data_l,\n",
    "            selected_data_c,\n",
    "            selected_data_r,\n",
    "            selected_data_l_correct,\n",
    "            selected_data_r_correct,\n",
    "        ),\n",
    "        1,\n",
    "    ):\n",
    "        row_html = '<div style=\"display: flex; align-items: center; margin: 5px 0;\">'\n",
    "\n",
    "        # Add row number\n",
    "        row_html += (\n",
    "            '<span style=\"margin-right: 10px; font-weight: bold;'\n",
    "            f' width: 30px; text-align: center;\">{idx}.</span>'\n",
    "        )\n",
    "\n",
    "        # Left side (blue background and orange background)\n",
    "        for i, (text, value) in enumerate(zip(text_data, row_data_l)):\n",
    "            if value > 0:\n",
    "                opacity = float(value / selected_data_lr_max)\n",
    "                style = f\"{base_style} background: rgba(173, 216, 230, {opacity});\"\n",
    "            else:\n",
    "                opacity = (\n",
    "                    float(abs(value) / selected_data_lr_max)\n",
    "                    if selected_data_lr_max != 0\n",
    "                    else 0\n",
    "                )\n",
    "                style = f\"{base_style} background: rgba(255, 218, 185, {opacity});\"\n",
    "\n",
    "            # color last token green if correct, red if incorrect\n",
    "            if i == 4:\n",
    "                if row_data_l_correct:\n",
    "                    style += \"border: 2px solid green;\"\n",
    "                else:\n",
    "                    style += \"border: 2px dashed red;\"\n",
    "            row_html += f'<span style=\"{style}\">{token_to_text(text)}</span>'\n",
    "\n",
    "        # Add separator\n",
    "        row_html += '<span style=\"margin: 0 10px;\">|</span>'\n",
    "\n",
    "        # Center side (green background)\n",
    "        for text, value in zip(text_data, row_data_c):\n",
    "            opacity = (\n",
    "                float(value / selected_data_c_max) if selected_data_c_max != 0 else 0\n",
    "            )\n",
    "            style = f\"{base_style} background: rgba(128, 222, 105, {opacity});\"\n",
    "            row_html += f'<span style=\"{style}\">{token_to_text(text)}</span>'\n",
    "\n",
    "        # Add separator\n",
    "        row_html += '<span style=\"margin: 0 10px;\">|</span>'\n",
    "\n",
    "        # Right side (light orange background)\n",
    "        for i, (text, value) in enumerate(zip(text_data, row_data_r)):\n",
    "            if value > 0:\n",
    "                opacity = float(value / selected_data_lr_max)\n",
    "                style = f\"{base_style} background: rgba(173, 216, 230, {opacity});\"\n",
    "            else:\n",
    "                opacity = float(abs(value) / selected_data_lr_max)\n",
    "                style = f\"{base_style} background: rgba(255, 218, 185, {opacity});\"\n",
    "\n",
    "            # color last token green if correct, red if incorrect\n",
    "            if i == 4:\n",
    "                if row_data_r_correct:\n",
    "                    style += \"border: 2px solid green;\"\n",
    "                else:\n",
    "                    style += \"border: 2px dashed red;\"\n",
    "            row_html += f'<span style=\"{style}\">{token_to_text(text)}</span>'\n",
    "\n",
    "        row_html += \"</div>\"\n",
    "        html_parts.append(row_html)\n",
    "\n",
    "    return headers_html, html_parts\n",
    "\n",
    "\n",
    "# Create an output widget for the plot that will be reused\n",
    "plot_output = ipywidgets.Output()\n",
    "\n",
    "# Create a single HTML widget for all the rows\n",
    "rows_html = ipywidgets.HTML()\n",
    "\n",
    "\n",
    "def update_display(change):\n",
    "    element_idx = change[\"new\"]\n",
    "\n",
    "    # Update the plot\n",
    "    with plot_output:\n",
    "        plot_output.clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 2))  # Smaller figure for faster rendering\n",
    "        fig = create_slider_plot(addition_relative_norms[element_idx])\n",
    "        plt.show(fig)\n",
    "\n",
    "    # Update the HTML content\n",
    "    headers_html, rows_html_parts = generate_html_for_element(element_idx)\n",
    "    full_html = headers_html + \"\".join(rows_html_parts)\n",
    "    rows_html.value = full_html\n",
    "\n",
    "\n",
    "# Connect dropdown to update function\n",
    "dropdown.observe(update_display, names=\"value\")\n",
    "\n",
    "# Connect button click handlers\n",
    "back_button.on_click(on_back_button_clicked)\n",
    "forward_button.on_click(on_forward_button_clicked)\n",
    "\n",
    "# Initial display\n",
    "update_display({\"new\": 0})\n",
    "\n",
    "# Create horizontal box for controls\n",
    "controls = ipywidgets.HBox([back_button, dropdown, forward_button])\n",
    "\n",
    "# Stack controls and display box vertically\n",
    "display_box = ipywidgets.VBox([plot_output, rows_html])\n",
    "vbox = ipywidgets.VBox([controls, display_box])\n",
    "display(vbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "train-sae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
